2025-06-12 18:37:04,213 - SailingRulesTrainer - INFO - Weights & Biases initialized. Project: sailing-rules-assistant, Run: flan-t5-16-epochs-10
Weights & Biases initialized. Project: sailing-rules-assistant, Run: flan-t5-16-epochs-10
[34m[1mwandb[0m: [33mWARNING[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
Track your training at: https://wandb.ai/dankj-jason-dank/sailing-rules-assistant/runs/u87n1esl
2025-06-12 18:37:04,214 - SailingRulesTrainer - INFO - Starting training preparation
Map:   0%|                                                                                                                                                                                          | 0/323 [00:00<?, ? examples/s]/Users/jasondank/PycharmProjects/Flan-t5-sailing/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 323/323 [00:00<00:00, 7370.72 examples/s]
2025-06-12 18:37:07,727 - SailingRulesTrainer - INFO - Using device: cpu
2025-06-12 18:37:07,747 - SailingRulesTrainer - WARNING - Warning: fp16 mixed precision is not supported on this device. Training with fp32 instead.
2025-06-12 18:37:07,748 - SailingRulesTrainer - INFO - Validation dataset is empty. Training without validation.
/Users/jasondank/PycharmProjects/Flan-t5-sailing/models/trainer.py:241: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(**trainer_kwargs)
You are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is
:DefaultFlowCallback
WandbCallback
No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
2025-06-12 18:37:08,216 - SailingRulesTrainer - INFO - Starting training with 323 examples for 10 epochs

==================================================
TRAINING STARTED
==================================================
Training logs are being saved to: training.log
Track training progress in real-time at: https://wandb.ai/dankj-jason-dank/sailing-rules-assistant/runs/u87n1esl
You can safely close this terminal - training will continue in the background.
==================================================
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                                                                                      | 0/810 [00:00<?, ?it/s]/Users/jasondank/PycharmProjects/Flan-t5-sailing/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.
  warnings.warn(warn_msg)
Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.
                                                                                                                                                                                                                                   

{'loss': 35.6484, 'grad_norm': 6.38567590713501, 'learning_rate': 4.5e-06, 'epoch': 0.12}
{'loss': 35.5413, 'grad_norm': 6.580613613128662, 'learning_rate': 9.5e-06, 'epoch': 0.25}
{'loss': 36.2059, 'grad_norm': 6.783841609954834, 'learning_rate': 1.45e-05, 'epoch': 0.37}
{'loss': 35.194, 'grad_norm': 5.202436447143555, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.49}
{'loss': 35.4505, 'grad_norm': 8.907642364501953, 'learning_rate': 2.45e-05, 'epoch': 0.62}
{'loss': 34.6165, 'grad_norm': 7.433456897735596, 'learning_rate': 2.95e-05, 'epoch': 0.74}
{'loss': 34.4507, 'grad_norm': 7.936572551727295, 'learning_rate': 3.45e-05, 'epoch': 0.86}
{'loss': 33.6843, 'grad_norm': 9.694764137268066, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.99}
{'loss': 32.4518, 'grad_norm': 8.386953353881836, 'learning_rate': 4.4500000000000004e-05, 'epoch': 1.11}
{'loss': 31.2875, 'grad_norm': 10.75993537902832, 'learning_rate': 4.9500000000000004e-05, 'epoch': 1.23}
{'loss': 30.1405, 'grad_norm': 10.363693237304688, 'learning_rate': 4.936619718309859e-05, 'epoch': 1.36}
{'loss': 29.2738, 'grad_norm': 7.476474761962891, 'learning_rate': 4.866197183098592e-05, 'epoch': 1.48}
{'loss': 27.5486, 'grad_norm': 7.350247859954834, 'learning_rate': 4.7957746478873244e-05, 'epoch': 1.6}
{'loss': 25.9288, 'grad_norm': 8.423116683959961, 'learning_rate': 4.725352112676056e-05, 'epoch': 1.73}
{'loss': 24.5505, 'grad_norm': 8.83059024810791, 'learning_rate': 4.654929577464789e-05, 'epoch': 1.85}
{'loss': 23.2387, 'grad_norm': 7.328764915466309, 'learning_rate': 4.5845070422535214e-05, 'epoch': 1.98}
{'loss': 21.1305, 'grad_norm': 10.48979377746582, 'learning_rate': 4.514084507042254e-05, 'epoch': 2.1}
{'loss': 19.5209, 'grad_norm': 8.790948867797852, 'learning_rate': 4.4436619718309865e-05, 'epoch': 2.22}
{'loss': 17.6743, 'grad_norm': 9.378870964050293, 'learning_rate': 4.373239436619718e-05, 'epoch': 2.35}
{'loss': 15.3897, 'grad_norm': 10.439240455627441, 'learning_rate': 4.302816901408451e-05, 'epoch': 2.47}
{'loss': 12.8382, 'grad_norm': 10.854515075683594, 'learning_rate': 4.2323943661971834e-05, 'epoch': 2.59}
{'loss': 10.2751, 'grad_norm': 10.412023544311523, 'learning_rate': 4.161971830985916e-05, 'epoch': 2.72}
{'loss': 8.2972, 'grad_norm': 5.065361499786377, 'learning_rate': 4.091549295774648e-05, 'epoch': 2.84}
{'loss': 6.7661, 'grad_norm': 3.8519716262817383, 'learning_rate': 4.0211267605633804e-05, 'epoch': 2.96}
{'loss': 5.836, 'grad_norm': 2.9667561054229736, 'learning_rate': 3.950704225352112e-05, 'epoch': 3.09}
{'loss': 5.4056, 'grad_norm': 1.585923194885254, 'learning_rate': 3.880281690140845e-05, 'epoch': 3.21}
{'loss': 5.1797, 'grad_norm': 1.181266188621521, 'learning_rate': 3.8098591549295774e-05, 'epoch': 3.33}
{'loss': 5.0752, 'grad_norm': 0.8372135162353516, 'learning_rate': 3.73943661971831e-05, 'epoch': 3.46}
{'loss': 4.9594, 'grad_norm': 0.8026716113090515, 'learning_rate': 3.6690140845070425e-05, 'epoch': 3.58}
{'loss': 4.8514, 'grad_norm': 0.851057231426239, 'learning_rate': 3.598591549295775e-05, 'epoch': 3.7}
{'loss': 4.8361, 'grad_norm': 0.6432007551193237, 'learning_rate': 3.528169014084507e-05, 'epoch': 3.83}
{'loss': 4.7438, 'grad_norm': 0.6543511152267456, 'learning_rate': 3.4577464788732395e-05, 'epoch': 3.95}
{'loss': 4.72, 'grad_norm': 0.68235182762146, 'learning_rate': 3.387323943661972e-05, 'epoch': 4.07}
{'loss': 4.643, 'grad_norm': 0.5799514651298523, 'learning_rate': 3.3169014084507046e-05, 'epoch': 4.2}
{'loss': 4.5879, 'grad_norm': 0.6096490621566772, 'learning_rate': 3.246478873239437e-05, 'epoch': 4.32}
{'loss': 4.5495, 'grad_norm': 0.8586055636405945, 'learning_rate': 3.17605633802817e-05, 'epoch': 4.44}
{'loss': 4.4945, 'grad_norm': 0.6660680174827576, 'learning_rate': 3.1056338028169016e-05, 'epoch': 4.57}
{'loss': 4.4596, 'grad_norm': 0.9811722040176392, 'learning_rate': 3.0352112676056338e-05, 'epoch': 4.69}
{'loss': 4.4068, 'grad_norm': 0.8145490288734436, 'learning_rate': 2.9647887323943664e-05, 'epoch': 4.81}
{'loss': 4.3228, 'grad_norm': 0.9935279488563538, 'learning_rate': 2.894366197183099e-05, 'epoch': 4.94}
{'loss': 4.2938, 'grad_norm': 1.3434652090072632, 'learning_rate': 2.823943661971831e-05, 'epoch': 5.06}
{'loss': 4.2426, 'grad_norm': 1.1235113143920898, 'learning_rate': 2.7535211267605637e-05, 'epoch': 5.19}
{'loss': 4.075, 'grad_norm': 1.1462819576263428, 'learning_rate': 2.6830985915492955e-05, 'epoch': 5.31}
{'loss': 4.0074, 'grad_norm': 1.5153378248214722, 'learning_rate': 2.612676056338028e-05, 'epoch': 5.43}
{'loss': 4.0139, 'grad_norm': 2.7048864364624023, 'learning_rate': 2.5422535211267607e-05, 'epoch': 5.56}
{'loss': 3.8687, 'grad_norm': 1.7077869176864624, 'learning_rate': 2.4718309859154932e-05, 'epoch': 5.68}
{'loss': 3.7929, 'grad_norm': 2.790414810180664, 'learning_rate': 2.4014084507042258e-05, 'epoch': 5.8}
{'loss': 3.7621, 'grad_norm': 2.169116735458374, 'learning_rate': 2.3309859154929576e-05, 'epoch': 5.93}
{'loss': 3.7195, 'grad_norm': 2.519355535507202, 'learning_rate': 2.2605633802816902e-05, 'epoch': 6.05}
{'loss': 3.661, 'grad_norm': 1.1268924474716187, 'learning_rate': 2.1901408450704227e-05, 'epoch': 6.17}
{'loss': 3.551, 'grad_norm': 1.3238317966461182, 'learning_rate': 2.119718309859155e-05, 'epoch': 6.3}
{'loss': 3.4664, 'grad_norm': 1.3197295665740967, 'learning_rate': 2.0492957746478875e-05, 'epoch': 6.42}
{'loss': 3.4437, 'grad_norm': 1.8263617753982544, 'learning_rate': 1.9788732394366197e-05, 'epoch': 6.54}
{'loss': 3.4565, 'grad_norm': 2.461974620819092, 'learning_rate': 1.9084507042253523e-05, 'epoch': 6.67}
{'loss': 3.4019, 'grad_norm': 2.105285406112671, 'learning_rate': 1.8380281690140845e-05, 'epoch': 6.79}
{'loss': 3.3605, 'grad_norm': 1.3768517971038818, 'learning_rate': 1.7676056338028167e-05, 'epoch': 6.91}
  warnings.warn(warn_msg)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 810/810 [22:10<00:00,  1.64s/it]
{'loss': 3.3426, 'grad_norm': 2.237753391265869, 'learning_rate': 1.6971830985915493e-05, 'epoch': 7.04}
{'loss': 3.323, 'grad_norm': 2.0499415397644043, 'learning_rate': 1.6267605633802818e-05, 'epoch': 7.16}
{'loss': 3.3378, 'grad_norm': 1.7262005805969238, 'learning_rate': 1.556338028169014e-05, 'epoch': 7.28}
{'loss': 3.2063, 'grad_norm': 1.345441460609436, 'learning_rate': 1.4859154929577466e-05, 'epoch': 7.41}
{'loss': 3.2082, 'grad_norm': 1.2652385234832764, 'learning_rate': 1.415492957746479e-05, 'epoch': 7.53}
{'loss': 3.0874, 'grad_norm': 2.188324451446533, 'learning_rate': 1.3450704225352112e-05, 'epoch': 7.65}
{'loss': 3.1439, 'grad_norm': 1.5065003633499146, 'learning_rate': 1.2746478873239437e-05, 'epoch': 7.78}
{'loss': 3.0726, 'grad_norm': 1.605648159980774, 'learning_rate': 1.2042253521126761e-05, 'epoch': 7.9}
{'loss': 3.0329, 'grad_norm': 1.3507509231567383, 'learning_rate': 1.1338028169014085e-05, 'epoch': 8.02}
{'loss': 3.0785, 'grad_norm': 2.1504156589508057, 'learning_rate': 1.0633802816901409e-05, 'epoch': 8.15}
{'loss': 3.0182, 'grad_norm': 2.0683579444885254, 'learning_rate': 9.929577464788733e-06, 'epoch': 8.27}
{'loss': 3.0312, 'grad_norm': 1.800345778465271, 'learning_rate': 9.225352112676057e-06, 'epoch': 8.4}
{'loss': 2.9491, 'grad_norm': 1.9392293691635132, 'learning_rate': 8.52112676056338e-06, 'epoch': 8.52}
{'loss': 3.0113, 'grad_norm': 2.1425631046295166, 'learning_rate': 7.816901408450706e-06, 'epoch': 8.64}
{'loss': 2.9536, 'grad_norm': 1.4805538654327393, 'learning_rate': 7.112676056338029e-06, 'epoch': 8.77}
{'loss': 2.9385, 'grad_norm': 1.4991929531097412, 'learning_rate': 6.408450704225352e-06, 'epoch': 8.89}
{'loss': 2.9386, 'grad_norm': 1.7438308000564575, 'learning_rate': 5.7042253521126766e-06, 'epoch': 9.01}
{'loss': 2.9549, 'grad_norm': 2.381476640701294, 'learning_rate': 5e-06, 'epoch': 9.14}
{'loss': 2.8991, 'grad_norm': 1.6449942588806152, 'learning_rate': 4.295774647887324e-06, 'epoch': 9.26}
{'loss': 2.9105, 'grad_norm': 1.4767013788223267, 'learning_rate': 3.591549295774648e-06, 'epoch': 9.38}
{'loss': 2.931, 'grad_norm': 1.6541101932525635, 'learning_rate': 2.887323943661972e-06, 'epoch': 9.51}
{'loss': 2.9329, 'grad_norm': 1.9618717432022095, 'learning_rate': 2.1830985915492958e-06, 'epoch': 9.63}
{'loss': 2.8772, 'grad_norm': 1.6020835638046265, 'learning_rate': 1.4788732394366198e-06, 'epoch': 9.75}
{'loss': 2.8379, 'grad_norm': 1.5933053493499756, 'learning_rate': 7.746478873239438e-07, 'epoch': 9.88}
{'loss': 2.9144, 'grad_norm': 1.617263913154602, 'learning_rate': 7.042253521126761e-08, 'epoch': 10.0}
{'train_runtime': 1330.8192, 'train_samples_per_second': 2.427, 'train_steps_per_second': 0.609, 'train_loss': 10.249681178434395, 'epoch': 10.0}
2025-06-12 18:59:19,153 - SailingRulesTrainer - INFO - Training completed successfully
2025-06-12 18:59:19,156 - SailingRulesTrainer - INFO - Saving model to models/sailing_rules_assistant
